{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3e30e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "X_train \n",
    "y_train \n",
    "model_train\n",
    "compute_cost\n",
    "compute_gradient\n",
    "gradient_descent\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "96f1edaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "np.set_printoptions(precision=2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d14e8b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array([[2104, 5, 1, 45], [1416, 3, 2, 40], [852, 2, 1, 35]])\n",
    "y_train = np.array([460, 232, 178])\n",
    "b_init = 785.1811367994083\n",
    "w_init = np.array([ 0.39133535, 18.75376741, -53.36032453, -26.42131618])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f42e5047",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_wb(x, w, b):\n",
    "    \"\"\"\n",
    "    f_wb(x) = dot(w,x)+b\n",
    "    \"\"\"\n",
    "    f_wb = np.dot(w,x) +b\n",
    "    return f_wb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae6fd88b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "459.9999976194082"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_wb(X_train[0], w_init, b_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "22209a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(x, y, w, b):\n",
    "    \"\"\"\n",
    "    j_wb(x) = 1/2m sum_im (f_wb - y[i])**2\n",
    "    \"\"\"\n",
    "    n = x.shape[0]\n",
    "    cost = 0\n",
    "    for i in range(n):\n",
    "        f_wb = np.dot(w,x[i]) +b\n",
    "        cost += (f_wb -y[i])**2\n",
    "    total_cost = 1/(2*n) *cost\n",
    "    return total_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5a3c9b62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5578904330213735e-12"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_cost(X_train, y_train, w_init, b_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2bbc7dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient(x, y, w, b):\n",
    "    \"\"\"\n",
    "    dj_dw = 1/m sum_im(f_wb -y)*x\n",
    "    dj_db = 1/m sum_im(f_wb -y)\n",
    "    \"\"\"\n",
    "    \n",
    "    m,n =x.shape\n",
    "    dj_dw = np.zeros(n,) \n",
    "    dj_db =0 \n",
    "    for i in range(m):\n",
    "        err = (np.dot(w,x[i])+b)-y[i]\n",
    "        for j in range(n):\n",
    "            dj_dw[j] =dj_dw[j] + (err* x[i,j])\n",
    "        dj_db = dj_db +err\n",
    "    dj_dw /=m\n",
    "    dj_db /=m\n",
    "    return dj_dw, dj_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6babe232",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-2.73e-03, -6.27e-06, -2.22e-06, -6.92e-05]), -1.6739251122999121e-06)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_gradient(X_train, y_train, w_init, b_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dd8d1396",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(x, y, w_in, b_in, compute_cost, compute_gradient, alpha, iter_num):\n",
    "    \"\"\"\n",
    "    w =w- alpha dj_dw\n",
    "    b =b- alpha dj_db\n",
    "    \"\"\"\n",
    "    j_hist=[]\n",
    "    W_hist =np.empty([iter_num,4])\n",
    "    w =copy.deepcopy(w_in)\n",
    "    b= b_in\n",
    "    \n",
    "    for i in range(iter_num):\n",
    "        dj_dw, dj_db = compute_gradient(x, y, w, b)\n",
    "        w = w- alpha * dj_dw\n",
    "        b = b- alpha * dj_db\n",
    "        W_hist[i]=w\n",
    "        if i< 100000:\n",
    "            j_hist.append(compute_cost(x, y, w, b))\n",
    "        \n",
    "        \n",
    "    return w, b, J_history, W_hist     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "83c1c81d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'J_history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9384\\3856565698.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0malpha\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.0e-8\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mw_final\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb_final\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mJ_hist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW_hist\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mgradient_descent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial_w\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial_b\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompute_cost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompute_gradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"b,w found by gradient descent: {b_final:0.2f},{w_final} \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9384\\1688340851.py\u001b[0m in \u001b[0;36mgradient_descent\u001b[1;34m(x, y, w_in, b_in, compute_cost, compute_gradient, alpha, iter_num)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mJ_history\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW_hist\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'J_history' is not defined"
     ]
    }
   ],
   "source": [
    "initial_w = np.zeros_like(w_init)\n",
    "initial_b = 0.\n",
    "iterations = 100000\n",
    "alpha = 1.0e-8\n",
    "\n",
    "w_final, b_final, J_hist, W_hist =gradient_descent(X_train, y_train, initial_w, initial_b, compute_cost, compute_gradient, alpha, iterations)\n",
    "print(f\"b,w found by gradient descent: {b_final:0.2f},{w_final} \")\n",
    "m,_ = X_train.shape\n",
    "for i in range(m):\n",
    "    print(f\"prediction: {np.dot(X_train[i], w_final) + b_final:0.2f}, target value: {y_train[i]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
